{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9458450,"sourceType":"datasetVersion","datasetId":5750004},{"sourceId":10669430,"sourceType":"datasetVersion","datasetId":6608148}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code]\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-03-06T09:30:05.376909Z\",\"iopub.execute_input\":\"2025-03-06T09:30:05.377322Z\",\"iopub.status.idle\":\"2025-03-06T09:30:05.383511Z\",\"shell.execute_reply.started\":\"2025-03-06T09:30:05.377250Z\",\"shell.execute_reply\":\"2025-03-06T09:30:05.382277Z\"}}\n# src/preprocessing.py\n\nimport os\nimport shutil\nimport torch\nimport random\nfrom PIL import Image\nfrom torchvision import transforms, datasets\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-03-06T09:30:24.786860Z\",\"iopub.execute_input\":\"2025-03-06T09:30:24.787211Z\",\"iopub.status.idle\":\"2025-03-06T09:30:24.798396Z\",\"shell.execute_reply.started\":\"2025-03-06T09:30:24.787174Z\",\"shell.execute_reply\":\"2025-03-06T09:30:24.797046Z\"},\"jupyter\":{\"outputs_hidden\":false}}\ndef split_dataset(source_dir, output_dir, train_ratio, seed=42):\n        \"\"\"\n        Split a dataset into training and validation sets.\n        \n        Args:\n            source_dir (str): Directory containing class folders with images\n            output_dir (str): Directory to save the split datasets\n            train_ratio (float): Proportion of images to use for training\n            seed (int): Random seed for reproducibility\n        \n        Returns:\n            tuple: Paths to train and validation directories\n        \"\"\"\n        random.seed(seed)\n        \n        # Create output directories\n        train_dir = os.path.join(output_dir, 'train')\n        test_dir = os.path.join(output_dir, 'test')\n        \n        # Create directories if they don't exist\n        os.makedirs(train_dir, exist_ok=True)\n        os.makedirs(test_dir, exist_ok=True)\n        \n        # Get all class folders\n        class_folders = sorted([d for d in os.listdir(source_dir) \n                         if os.path.isdir(os.path.join(source_dir, d))])\n        \n        for class_folder in class_folders:\n            # Create class directories in train and test\n            os.makedirs(os.path.join(train_dir, class_folder), exist_ok=True)\n            os.makedirs(os.path.join(test_dir, class_folder), exist_ok=True)\n            \n            # Get all images in class folder\n            src_class_dir = os.path.join(source_dir, class_folder)\n            images = [f for f in os.listdir(src_class_dir) if _is_image_file(f)]\n            \n            # Shuffle images\n            random.shuffle(images)\n            \n            # Split based on ratio\n            train_count = int(len(images) * train_ratio)\n            train_images = images[:train_count]\n            test_images = images[train_count:]\n            \n            # Copy images to respective directories\n            for img in train_images:\n                shutil.copy(\n                    os.path.join(src_class_dir, img),\n                    os.path.join(train_dir, class_folder, img)\n                )\n            \n            for img in test_images:\n                shutil.copy(\n                    os.path.join(src_class_dir, img),\n                    os.path.join(test_dir, class_folder, img)\n                )\n            \n            print(f\"Class {class_folder}: {len(train_images)} training images, {len(test_images)} testing images\")\n        \n        return train_dir, test_dir\n\ndef _is_image_file(filename):\n    \"\"\"Check if file is an image based on extension.\"\"\"\n    img_extensions = ['.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.tif', '.tiff']\n    return any(filename.lower().endswith(ext) for ext in img_extensions)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-03-06T09:30:27.897534Z\",\"iopub.execute_input\":\"2025-03-06T09:30:27.897867Z\",\"iopub.status.idle\":\"2025-03-06T09:30:27.904840Z\",\"shell.execute_reply.started\":\"2025-03-06T09:30:27.897837Z\",\"shell.execute_reply\":\"2025-03-06T09:30:27.903667Z\"},\"jupyter\":{\"outputs_hidden\":false}}\ndef get_transforms(train=True, input_size=224):\n    \"\"\"Create transform pipeline for training or testing.\"\"\"\n    if train:\n        return transforms.Compose([\n            transforms.Resize(size=(224, 224)),\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n            transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n    else:\n        return transforms.Compose([\n            transforms.Resize(size=(224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-03-06T09:30:29.304809Z\",\"iopub.execute_input\":\"2025-03-06T09:30:29.305312Z\",\"iopub.status.idle\":\"2025-03-06T09:30:29.316929Z\",\"shell.execute_reply.started\":\"2025-03-06T09:30:29.305266Z\",\"shell.execute_reply\":\"2025-03-06T09:30:29.315252Z\"},\"jupyter\":{\"outputs_hidden\":false}}\ndef create_dataloaders(data_dir, train, batch_size=32, num_workers=os.cpu_count()):\n    \"\"\"Create training and testing data loaders.\"\"\"\n\n    if train==True:\n        # Create datasets\n        train_dataset = datasets.ImageFolder(\n            root=data_dir,\n            transform=get_transforms(train=True)\n        )\n        classes = train_dataset.classes\n        \n        # Create dataloaders\n        train_loader = torch.utils.data.DataLoader(\n            train_dataset,\n            batch_size=batch_size,\n            shuffle=True,\n            num_workers=num_workers,\n            pin_memory=True\n        )\n        \n        return train_loader, classes\n    else:\n        # Create datasets\n        test_dataset = datasets.ImageFolder(\n            root=data_dir,\n            transform=get_transforms(train=False)\n        )\n        \n        # Create dataloaders\n        test_loader = torch.utils.data.DataLoader(\n            test_dataset,\n            batch_size=batch_size,\n            shuffle=False,\n            num_workers=num_workers,\n            pin_memory=True\n        )\n   \n        return test_loader","metadata":{"_uuid":"d9ac0353-136a-4ca6-8fe1-3206b0c7e671","_cell_guid":"2749601f-37b2-43f8-b729-ac498ddb2be7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}